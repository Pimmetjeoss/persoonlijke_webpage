---
title: "DeepSeek-OCR: Van Tekst naar Beeld"
date: "2025-10-20"
category: "AI & Technologie"
excerpt: "De bewering van 10x compressie klinkt onmogelijk. De waarheid is subtieler - en revolutionair: AI die visueel denkt in plaats van in woorden."
---

# DeepSeek-OCR: Van Tekst naar Beeld

## 1.0 Introductie: de onmogelijke bewering

Recentelijk is er veel ophef ontstaan rond een nieuw AI-model genaamd **DeepSeek-OCR**. De claim die de krantenkoppen domineert, is ronduit spectaculair: dit model kan data maar liefst **10 keer kleiner comprimeren**.

Voor iedereen met een beetje kennis van informatietheorie klinkt dit als pure sciencefiction. Er is namelijk een harde, wiskundige grens aan hoe ver je data kunt samenpersen zonder informatie te verliezen, een concept dat bekendstaat als **'entropie'**.

### Het scepsis moment

Toen DeepSeek dus aankondigde deze fundamentele limiet te doorbreken, zorgde dat voor een golf van verbazing en scepsis. Hoe is dit mogelijk? Hebben ze een van de basiswetten van informatie gekraakt?

De waarheid is subtieler en, eerlijk gezegd, nog veel interessanter dan de sensationele headlines.

In deze blogpost duiken we in wat er écht aan de hand is. We ontrafelen de mythe van de "10x compressie" en leggen de werkelijk baanbrekende innovatie bloot die hierachter schuilgaat.

## 2.0 De grote onthulling: 5 verrassende inzichten over DeepSeek's revolutie

DeepSeek's methode is geen tovenarij, maar een briljant staaltje 'out of the box'-denken. Het forceert ons om de fundamentele aannames over hoe AI taal verwerkt, opnieuw te evalueren.

Hier zijn de vijf inzichten die er echt toe doen.

## 2.1 Inzicht 1: de "10x compressie" gaat over representatie, niet over bestandsgrootte

Dit is de cruciale nuance die vaak over het hoofd wordt gezien: **DeepSeek-OCR maakt je tekstbestanden niet 10 keer kleiner op je harde schijf**. Sterker nog, een afbeelding van tekst neemt juist meer opslagruimte in dan de tekst zelf.

### Representatie-efficiëntie

De doorbraak zit in **'representatie-efficiëntie'**. Dit gaat over hoe compact de informatie is verpakt voor het AI-model zelf.

Vergelijk het met het verschil tussen:
- Een woordelijke transcriptie van een vergadering (inefficiënt, zoals oude methodes)
- Een beknopte samenvatting van alleen de belangrijkste beslissingen (extreem efficiënt, zoals DeepSeek's aanpak)

Beide bevatten de kerninformatie, maar de laatste is vele malen compacter. **De winst zit dus niet in opslag, maar in de efficiëntie waarmee de AI informatie intern verwerkt.**

## 2.2 Inzicht 2: onze oude methode (tokens) was nooit ontworpen voor compactheid

Om de genialiteit van DeepSeek te waarderen, moeten we de oude methode begrijpen. Traditioneel 'lezen' AI's taal via **'tokens'**. Simpel gezegd is dit een systeem waarbij woorden of woorddelen worden omgezet in unieke nummers, zodat een computer ermee kan rekenen.

### De prioriteit lag elders

Deze aanpak is echter nooit gekozen voor zijn compactheid. De prioriteit lag bij **rekenkracht en schaalbaarheid**; het was een praktische manier om taal op grote schaal verwerkbaar te maken.

Menselijke taal is van nature overbodig en herhalend. Tokens waren een rekenkundig handige, maar **inefficiënte** manier om daarmee om te gaan.

### De bottleneck

Dit creëerde een enorme bottleneck: er was een harde limiet aan hoeveel tekst je een AI tegelijk kon voeren, het probleem dat DeepSeek nu slim omzeilt.

## 2.3 Inzicht 3: DeepSeek 'denkt' in beelden om het probleem te omzeilen

DeepSeek gooit het token-systeem overboord. In plaats van tekst woord voor woord te analyseren, gebruikt het een **visiemodel om naar een afbeelding van de tekst te kijken**.

### De latente ruimte

Vervolgens wordt alle informatie uit die afbeelding samengeperst in een **'latente ruimte'**. Zie de 'latente ruimte' als een soort conceptuele 'zip-file'.

Het model kijkt niet naar de letters 'A-P-P-E-L', maar roept direct het complete concept 'appel' op in zijn 'geheugen'—inclusief kleur, vorm en smaak. Deze conceptuele representatie is vele malen compacter dan de losse letters.

### De resultaten

De resultaten zijn verbluffend:
- Het model haalt **10x compressie met 97% nauwkeurigheid**
- Bij **20x compressie** is de nauwkeurigheid nog steeds **60%**

## 2.4 Inzicht 4: een top-expert vond de oude methode toch al niks

Deze frustratie met tokens is geen nicheprobleem; het wordt gedeeld aan de absolute top van de AI-wereld. **Andrej Karpathy**, een van de grondleggers van moderne AI, verwoordde het ongenoegen als volgt:

> "Verwijder de tokenizer bij de input. Ik heb al eens gerant over hoezeer ik de tokenizer haat. Tokenizers zijn lelijk, een aparte niet end-to-end fase. Het importeert alle lelijkheid van unicode door het te coderen. Het erft een hoop historische bagage, veiligheids- en jailbreakrisico's. Het zorgt ervoor dat twee karakters die er voor het oog identiek uitzien er intern in het netwerk uitzien als twee compleet verschillende tokens. De tokenizer moet weg."

## 2.5 Inzicht 5: de toekomst is misschien een AI die visueel denkt

Dit alles wijst op een mogelijke **paradigmaverschuiving**. Wellicht evolueren we naar een toekomst waarin AI-modellen primair worden getraind om **'in beelden te denken'** in plaats van in woorden.

### Een nieuw recept

Het fascinerende is dat de echte innovatie van DeepSeek niet in één specifieke nieuwe uitvinding zit. De doorbraak is een **slimme compositie van bestaande technologieën**, zoals:

- **SAM** (Segment Anything Model)
- **CNN's** (Convolutional Neural Networks)
- **Visiemodellen**

Het is geen nieuw ingrediënt, maar een compleet nieuw recept.

## 3.0 Conclusie: een nieuw paradigma voor AI?

De kern van DeepSeek's innovatie is de verschuiving van inefficiënte tekst-tokens naar dichte, op beelden gebaseerde representaties. Dit is meer dan een technische optimalisatie; het is een **fundamenteel andere manier van denken** over hoe een AI informatie kan begrijpen en verwerken.

### De kritieke vraag voor de industrie

Dit roept direct een cruciale vraag op voor de toekomst van de hele industrie: **hoe zal 'context engineering' er in de toekomst uitzien, nu zoveel AI-bedrijven gebouwd zijn rond het managen van tekst-context?**

**Key takeaways:**
- DeepSeek-OCR uitgebracht op 20 oktober 2025
- 3 miljard parameters vision-language model (VLM)
- 10x compressie met 97% nauwkeurigheid mogelijk
- 20x compressie met 60% nauwkeurigheid
- 200.000+ pagina's per dag op één A100-40G GPU
- Gebruikt "Contexts Optical Compression" in plaats van tokens
- Informatie wordt samengeperst in 'latente ruimte'
- Shift van tekst-tokens naar beeld-gebaseerde representaties
- Open-source: codes en model weights publiek beschikbaar
- Ondersteuning in vLLM vanaf 23 oktober 2025

---

*Deze analyse is gebaseerd op de release van DeepSeek-OCR op 20 oktober 2025 en het arXiv paper gepubliceerd op 21 oktober 2025.*

**Bronnen:**
- [TechNode: DeepSeek releases new OCR model](https://technode.com/2025/10/21/deepseek-releases-new-ocr-model-capable-of-generating-200000-pages-daily-on-a-single-gpu/)
- [GitHub: DeepSeek-OCR Repository](https://github.com/deepseek-ai/DeepSeek-OCR)
- [arXiv: DeepSeek-OCR Paper](https://arxiv.org/abs/2510.18234)
